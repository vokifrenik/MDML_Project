{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fingerprint: Coulomb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Coulomb'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16556\\1102052760.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mCoulomb\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel_selection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunctional\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mF\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Coulomb'"
     ]
    }
   ],
   "source": [
    "from Coulomb import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.model_selection import KFold  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=251)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Normalize the target (hform)\n",
    "target_scaler = MinMaxScaler()  # You can use StandardScaler if needed\n",
    "y_train = target_scaler.fit_transform(y_train.reshape(-1, 1) if isinstance(y_train, np.ndarray) else y_train.to_numpy().reshape(-1, 1))\n",
    "y_test = target_scaler.transform(y_test.reshape(-1, 1) if isinstance(y_test, np.ndarray) else y_test.to_numpy().reshape(-1, 1))\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "X_train = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train = torch.tensor(y_train, dtype=torch.float32)\n",
    "X_test = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test = torch.tensor(y_test, dtype=torch.float32)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the neural network\n",
    "class RegressionNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(RegressionNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_dim, 256)  # Increased neurons\n",
    "        self.bn1 = nn.BatchNorm1d(256)  # Batch normalization\n",
    "        self.fc2 = nn.Linear(256, 128)\n",
    "        self.bn2 = nn.BatchNorm1d(128)\n",
    "        self.fc3 = nn.Linear(128, 64)\n",
    "        self.bn3 = nn.BatchNorm1d(64)\n",
    "        self.fc4 = nn.Linear(64, 1)\n",
    "        self.dropout = nn.Dropout(p=0.2)  # Dropout to reduce overfitting\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.bn1(self.fc1(x)))  # LeakyReLU activation\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.bn2(self.fc2(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = F.leaky_relu(self.bn3(self.fc3(x)))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc4(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Define cross-validation training loop with train_test_split\n",
    "def cross_val_train(model_class, X_train, y_train, epochs, k_folds):\n",
    "    kfold = KFold(n_splits=k_folds, shuffle=True, random_state=42)\n",
    "    fold_results = []\n",
    "    best_val_loss = float('inf')\n",
    "    best_model_state = None\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(X_train)):\n",
    "        print(f\"\\nFold {fold + 1}/{k_folds}\")\n",
    "\n",
    "        # Use train_test_split to split the fold's training data\n",
    "        X_fold_train, X_val, y_fold_train, y_val = train_test_split(\n",
    "            X_train[train_idx], y_train[train_idx], test_size=0.2, random_state=42\n",
    "        )\n",
    "\n",
    "        # Initialize model, optimizer, scheduler\n",
    "        model = model_class(X_fold_train.shape[1])\n",
    "        optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "        scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "        criterion = nn.MSELoss()\n",
    "\n",
    "        for epoch in range(epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(X_fold_train)\n",
    "            loss = criterion(outputs, y_fold_train)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Step the learning rate scheduler\n",
    "            scheduler.step()\n",
    "\n",
    "            # Evaluation phase\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                val_outputs = model(X_val)\n",
    "                val_loss = criterion(val_outputs, y_val)\n",
    "\n",
    "            # Convert MSE to RMSE for better interpretability\n",
    "            rmse = torch.sqrt(loss).item()\n",
    "            val_rmse = torch.sqrt(val_loss).item()\n",
    "\n",
    "            # Print RMSE every 50 epochs\n",
    "            if (epoch + 1) % 500 == 0:\n",
    "                print(f\"Epoch [{epoch + 1}/{epochs}], RMSE: {rmse:.4f}, Val RMSE: {val_rmse:.4f}\")\n",
    "\n",
    "        # Store final validation loss for the fold\n",
    "        fold_results.append(val_loss.item())\n",
    "\n",
    "        # Save the model state if it's the best so far\n",
    "        if val_loss.item() < best_val_loss:\n",
    "            best_val_loss = val_loss.item()\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    # Print overall results\n",
    "    print(\"\\nCross-Validation Results:\")\n",
    "    print(f\"Fold Losses: {fold_results}\")\n",
    "    print(f\"Mean Validation Loss: {np.mean(fold_results):.4f}\")\n",
    "    print(f\"Standard Deviation: {np.std(fold_results):.4f}\")\n",
    "\n",
    "    # Save the best model state\n",
    "    torch.save(best_model_state, \"best_model.pth\")\n",
    "    print(\"Best model saved as 'best_model.pth'.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1/5\n",
      "Epoch [500/1000], RMSE: 0.1842, Val RMSE: 0.1154\n",
      "Epoch [1000/1000], RMSE: 0.1805, Val RMSE: 0.1152\n",
      "\n",
      "Fold 2/5\n",
      "Epoch [500/1000], RMSE: 0.1616, Val RMSE: 0.1088\n",
      "Epoch [1000/1000], RMSE: 0.1570, Val RMSE: 0.1087\n",
      "\n",
      "Fold 3/5\n",
      "Epoch [500/1000], RMSE: 0.1830, Val RMSE: 0.1162\n",
      "Epoch [1000/1000], RMSE: 0.1797, Val RMSE: 0.1162\n",
      "\n",
      "Fold 4/5\n",
      "Epoch [500/1000], RMSE: 0.1572, Val RMSE: 0.1166\n",
      "Epoch [1000/1000], RMSE: 0.1578, Val RMSE: 0.1165\n",
      "\n",
      "Fold 5/5\n",
      "Epoch [500/1000], RMSE: 0.1575, Val RMSE: 0.1179\n",
      "Epoch [1000/1000], RMSE: 0.1573, Val RMSE: 0.1176\n",
      "\n",
      "Cross-Validation Results:\n",
      "Fold Losses: [0.013268917798995972, 0.011825833469629288, 0.013494801707565784, 0.013582686893641949, 0.013836064375936985]\n",
      "Mean Validation Loss: 0.0132\n",
      "Standard Deviation: 0.0007\n",
      "Best model saved as 'best_model.pth'.\n"
     ]
    }
   ],
   "source": [
    "# Initialize loss function\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# Perform cross-validation\n",
    "cross_val_train(RegressionNN, X_train, y_train, epochs=1000, k_folds=5)\n",
    "\n",
    "# Save the model\n",
    "# Example usage: torch.save(model.state_dict(), \"enhanced_regression_model.pth\")\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonia\\AppData\\Local\\Temp\\ipykernel_18588\\4051752618.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  model.load_state_dict(torch.load(\"best_model.pth\"))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], RMSE: 0.1154\n",
      "Epoch [200/1000], RMSE: 0.1105\n",
      "Epoch [300/1000], RMSE: 0.1091\n",
      "Epoch [400/1000], RMSE: 0.1096\n",
      "Epoch [500/1000], RMSE: 0.1085\n",
      "Epoch [600/1000], RMSE: 0.1095\n",
      "Epoch [700/1000], RMSE: 0.1089\n",
      "Epoch [800/1000], RMSE: 0.1094\n",
      "Epoch [900/1000], RMSE: 0.1094\n",
      "Epoch [1000/1000], RMSE: 0.1087\n",
      "Training on full dataset completed.\n",
      "\n",
      "Test RMSE: 0.1088\n",
      "Final model saved as 'final_model.pth'.\n"
     ]
    }
   ],
   "source": [
    "# Load the best model and train it on the full training set\n",
    "def train_on_full_data(model_class, X_train, y_train, X_test, y_test, criterion, epochs=100):\n",
    "    model = model_class(X_train.shape[1])\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "    scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=50, gamma=0.5)\n",
    "\n",
    "    # Load the best model state\n",
    "    model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train)\n",
    "        loss = criterion(outputs, y_train)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scheduler.step()\n",
    "\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            rmse = torch.sqrt(loss).item()\n",
    "            print(f\"Epoch [{epoch + 1}/{epochs}], RMSE: {rmse:.4f}\")\n",
    "\n",
    "    print(\"Training on full dataset completed.\")\n",
    "\n",
    "    # Evaluate on test set\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        test_outputs = model(X_test)\n",
    "        test_loss = criterion(test_outputs, y_test)\n",
    "        test_rmse = torch.sqrt(test_loss).item()\n",
    "        print(f\"\\nTest RMSE: {test_rmse:.4f}\")\n",
    "\n",
    "    # Save the final model\n",
    "    torch.save(model.state_dict(), \"final_model.pth\")\n",
    "    print(\"Final model saved as 'final_model.pth'.\")\n",
    "\n",
    "# Train the best model on the full training set and evaluate on test set\n",
    "train_on_full_data(RegressionNN, X_train, y_train, X_test, y_test, criterion, epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare submission to Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1000\n",
      "2000\n",
      "3000\n",
      "4000\n"
     ]
    }
   ],
   "source": [
    "cmats_test = cmats_train\n",
    "cmats_test = np.zeros((len(test),max_number_of_atoms**2))\n",
    "for i,atoms in enumerate(test.atoms):\n",
    "    if i%1000 == 0:\n",
    "        print(i)\n",
    "    cmats_test[i,:] = cm.create(atoms)\n",
    "print(len(cmats_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4000, 400)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_kaggle = pd.DataFrame(data=cmats_test, index=test.id)\n",
    "X_test_kaggle_scaled = scaler.transform(X_test_kaggle)\n",
    "X_test_kaggle_scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare Kaggle submission\n",
    "def prepare_kaggle_submission(model, X_test_scaled, test_ids, target_scaler, output_file):\n",
    "    # Convert standardized X_test_kaggle to PyTorch tensor\n",
    "    X_test_tensor = torch.tensor(X_test_scaled, dtype=torch.float32)\n",
    "\n",
    "    # Predict with the trained model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_scaled = model(X_test_tensor).numpy()\n",
    "\n",
    "    # Descend the scaled predictions to the original scale\n",
    "    y_pred_original = target_scaler.inverse_transform(y_pred_scaled)\n",
    "\n",
    "    # Create the submission DataFrame\n",
    "    submission_df = pd.DataFrame({\n",
    "        \"id\": test_ids,\n",
    "        \"hform\": y_pred_original.flatten()  # Ensure hform is a 1D array\n",
    "    })\n",
    "\n",
    "    # Save to CSV\n",
    "    submission_df.to_csv(output_file, index=False)\n",
    "    print(f\"Submission file saved as: {output_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission file saved as: submission_test.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonia\\AppData\\Local\\Temp\\ipykernel_18588\\1234778783.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  final_model.load_state_dict(torch.load(\"final_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "# File path for submission\n",
    "output_file = \"submission_test.csv\"\n",
    "\n",
    "# Ensure the final model is loaded\n",
    "final_model = RegressionNN(X_train.shape[1])\n",
    "final_model.load_state_dict(torch.load(\"final_model.pth\"))\n",
    "\n",
    "# Prepare the Kaggle submission\n",
    "prepare_kaggle_submission(final_model, X_test_kaggle_scaled, test.id, target_scaler, output_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on original scale: 0.5914\n",
      "\n",
      "Sample Predictions vs Actuals:\n",
      "     Actual  Predicted\n",
      "0 -0.033324  -0.432615\n",
      "1 -1.398727  -1.353785\n",
      "2 -1.187238  -1.172646\n",
      "3 -0.948828  -0.948329\n",
      "4  0.066191  -0.031278\n",
      "5 -1.202062  -1.796983\n",
      "6 -0.741397  -0.465481\n",
      "7 -3.545803  -1.047422\n",
      "8 -0.285965  -0.537511\n",
      "9 -1.561886  -1.168741\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Antonia\\AppData\\Local\\Temp\\ipykernel_18588\\1487160478.py:31: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  final_model.load_state_dict(torch.load(\"final_model.pth\"))\n"
     ]
    }
   ],
   "source": [
    "# Evaluate submission preparation on known test data\n",
    "def evaluate_submission_pipeline(model, X_test, y_test, target_scaler):\n",
    "    # Convert PyTorch tensor back to numpy for scaling compatibility\n",
    "    X_test_numpy = X_test.numpy()\n",
    "    \n",
    "    # Predict using the trained model\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_pred_scaled = model(X_test).numpy()\n",
    "\n",
    "    # Descend predictions back to original scale\n",
    "    y_pred_original = target_scaler.inverse_transform(y_pred_scaled)\n",
    "    y_test_original = target_scaler.inverse_transform(y_test.numpy())\n",
    "\n",
    "    # Calculate RMSE on original scale\n",
    "    rmse = np.sqrt(np.mean((y_pred_original - y_test_original) ** 2))\n",
    "    print(f\"RMSE on original scale: {rmse:.4f}\")\n",
    "\n",
    "    # Display some predictions vs. actuals\n",
    "    comparison_df = pd.DataFrame({\n",
    "        \"Actual\": y_test_original.flatten(),\n",
    "        \"Predicted\": y_pred_original.flatten()\n",
    "    }).head(10)\n",
    "    print(\"\\nSample Predictions vs Actuals:\")\n",
    "    print(comparison_df)\n",
    "\n",
    "    return comparison_df, rmse\n",
    "\n",
    "# Ensure the final model is loaded\n",
    "final_model = RegressionNN(X_train.shape[1])\n",
    "final_model.load_state_dict(torch.load(\"final_model.pth\"))\n",
    "\n",
    "# Evaluate submission pipeline on known data\n",
    "comparison_df, rmse = evaluate_submission_pipeline(final_model, X_test, y_test, target_scaler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[0.11333410441875458]\n",
    "[0.11041968315839767]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MDMLenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
